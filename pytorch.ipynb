{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "!pip install torchvision", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190314080403-0000\nKERNEL_ID = 95fa2bdc-3c5d-4c92-a5b4-c1956ebd6d91\nCollecting torchvision\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/01/03fd7e503c16b3dc262483e5555ad40974ab5da8b9879e164b56c1f4ef6f/torchvision-0.2.2.post3-py2.py3-none-any.whl (64kB)\n\u001b[K    100% |################################| 71kB 1.6MB/s eta 0:00:01\n\u001b[?25hCollecting numpy (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/18/4f013c3c3051f4e0ffbaa4bf247050d6d5e527fe9cb1907f5975b172f23f/numpy-1.16.2-cp35-cp35m-manylinux1_x86_64.whl (17.2MB)\n\u001b[K    100% |################################| 17.2MB 708kB/s eta 0:00:01\n\u001b[?25hCollecting six (from torchvision)\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nCollecting torch (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/d2/4e806f73b4b72daab9064c99394fc22ea6ef1fb052154546405057cd192d/torch-1.0.1.post2-cp35-cp35m-manylinux1_x86_64.whl (582.5MB)\n\u001b[K    100% |################################| 582.5MB 47kB/s  eta 0:00:01    19% |######                          | 112.8MB 49.3MB/s eta 0:00:10    95% |##############################  | 554.7MB 49.2MB/s eta 0:00:01\n\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/e9/5c47710fe383f0582da668302a80a6355fe15c2ce2dde89b50fe34acefa6/Pillow-5.4.1-cp35-cp35m-manylinux1_x86_64.whl (2.0MB)\n\u001b[K    100% |################################| 2.0MB 215kB/s eta 0:00:01\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n\u001b[31mpyspark 2.3.0 requires py4j==0.10.6, which is not installed.\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, six, torch, pillow, torchvision\nSuccessfully installed numpy-1.16.2 pillow-5.4.1 six-1.12.0 torch-1.0.1.post2 torchvision-0.2.2.post3\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "import torch ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 2
        }, 
        {
            "source": "print(torch.__version__)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "1.0.1.post2\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "tensor_array=torch.Tensor([[1,2],[4,5]])\ntensor_array", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[1., 2.],\n        [4., 5.]])"
                    }, 
                    "execution_count": 4, 
                    "metadata": {}
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "tensor_uninitialized=torch.Tensor(3,3)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "torch.numel(tensor_uninitialized)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "9"
                    }, 
                    "execution_count": 6, 
                    "metadata": {}
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "tensor_initialized=torch.rand(2,3)\ntensor_initialized", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.5763, 0.7253, 0.8157],\n        [0.4366, 0.5785, 0.9403]])"
                    }, 
                    "execution_count": 7, 
                    "metadata": {}
                }
            ], 
            "execution_count": 7
        }, 
        {
            "source": "tensor_int=torch.randn(5,3).type(torch.IntTensor)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 12
        }, 
        {
            "source": "torch.tensor([1.2,3]).dtype", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.float32"
                    }, 
                    "execution_count": 8, 
                    "metadata": {}
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "tensor_long=torch.LongTensor([1.0,2.0,3.0])\ntensor_long", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([1, 2, 3])"
                    }, 
                    "execution_count": 14, 
                    "metadata": {}
                }
            ], 
            "execution_count": 14
        }, 
        {
            "source": "tensor_byte=torch.ByteTensor([0,261,1,-5])\ntensor_byte", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([  0,   5,   1, 251], dtype=torch.uint8)"
                    }, 
                    "execution_count": 16, 
                    "metadata": {}
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "tensor_ones=torch.ones(10)\ntensor_ones", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
                    }, 
                    "execution_count": 17, 
                    "metadata": {}
                }
            ], 
            "execution_count": 17
        }, 
        {
            "source": "tensor_zeroes=torch.zeros(10)\ntensor_zeroes", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
                    }, 
                    "execution_count": 18, 
                    "metadata": {}
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "tensor_eye=torch.eye(3)\ntensor_eye", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
                    }, 
                    "execution_count": 19, 
                    "metadata": {}
                }
            ], 
            "execution_count": 19
        }, 
        {
            "source": "non_zero=torch.nonzero(tensor_eye)\nnon_zero", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0, 0],\n        [1, 1],\n        [2, 2]])"
                    }, 
                    "execution_count": 20, 
                    "metadata": {}
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "tensor_ones_shape_eye=torch.ones_like(tensor_eye)\ntensor_ones_shape_eye", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])"
                    }, 
                    "execution_count": 21, 
                    "metadata": {}
                }
            ], 
            "execution_count": 21
        }, 
        {
            "source": "initial_tensor=torch.rand(3,3)\ninitial_tensor.fill_(3)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[3., 3., 3.],\n        [3., 3., 3.],\n        [3., 3., 3.]])"
                    }, 
                    "execution_count": 23, 
                    "metadata": {}
                }
            ], 
            "execution_count": 23
        }, 
        {
            "source": "new_tensor=initial_tensor.add(4)\nnew_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[7., 7., 7.],\n        [7., 7., 7.],\n        [7., 7., 7.]])"
                    }, 
                    "execution_count": 24, 
                    "metadata": {}
                }
            ], 
            "execution_count": 24
        }, 
        {
            "source": "import numpy as np ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 25
        }, 
        {
            "source": "numpy_arr=np.array([1,2,3])\nnumpy_arr", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([1, 2, 3])"
                    }, 
                    "execution_count": 27, 
                    "metadata": {}
                }
            ], 
            "execution_count": 27
        }, 
        {
            "source": "tensor=torch.from_numpy(numpy_arr)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 28
        }, 
        {
            "source": "tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([1, 2, 3])"
                    }, 
                    "execution_count": 29, 
                    "metadata": {}
                }
            ], 
            "execution_count": 29
        }, 
        {
            "source": "numpy_from_tensor=tensor.numpy()\nnumpy_from_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([1, 2, 3])"
                    }, 
                    "execution_count": 30, 
                    "metadata": {}
                }
            ], 
            "execution_count": 30
        }, 
        {
            "source": "numpy_arr[1]=4\nnumpy_arr", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([1, 4, 3])"
                    }, 
                    "execution_count": 31, 
                    "metadata": {}
                }
            ], 
            "execution_count": 31
        }, 
        {
            "source": "tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([1, 4, 3])"
                    }, 
                    "execution_count": 32, 
                    "metadata": {}
                }
            ], 
            "execution_count": 32
        }, 
        {
            "source": "tensors and numpy share same memory ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "numpy_from_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([1, 4, 3])"
                    }, 
                    "execution_count": 33, 
                    "metadata": {}
                }
            ], 
            "execution_count": 33
        }, 
        {
            "source": "initial_tensor=torch.rand(2,3)\ninitial_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.7834, 0.1569, 0.2444],\n        [0.3895, 0.3012, 0.3274]])"
                    }, 
                    "execution_count": 34, 
                    "metadata": {}
                }
            ], 
            "execution_count": 34
        }, 
        {
            "source": "initial_tensor[0,2]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor(0.2444)"
                    }, 
                    "execution_count": 36, 
                    "metadata": {}
                }
            ], 
            "execution_count": 36
        }, 
        {
            "source": "initial_tensor[:,1:]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.1569, 0.2444],\n        [0.3012, 0.3274]])"
                    }, 
                    "execution_count": 37, 
                    "metadata": {}
                }
            ], 
            "execution_count": 37
        }, 
        {
            "source": "initial_tensor.size()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.Size([2, 3])"
                    }, 
                    "execution_count": 38, 
                    "metadata": {}
                }
            ], 
            "execution_count": 38
        }, 
        {
            "source": "initial_tensor.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.Size([2, 3])"
                    }, 
                    "execution_count": 40, 
                    "metadata": {}
                }
            ], 
            "execution_count": 40
        }, 
        {
            "source": "resized_tensor=initial_tensor.view(6)\nresized_tensor.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.Size([6])"
                    }, 
                    "execution_count": 42, 
                    "metadata": {}
                }
            ], 
            "execution_count": 42
        }, 
        {
            "source": "resized_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([0.7834, 0.1569, 0.2444, 0.3895, 0.3012, 0.3274])"
                    }, 
                    "execution_count": 43, 
                    "metadata": {}
                }
            ], 
            "execution_count": 43
        }, 
        {
            "source": "initial_tensor[0,2]=0.1111\nresized_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([0.7834, 0.1569, 0.1111, 0.3895, 0.3012, 0.3274])"
                    }, 
                    "execution_count": 45, 
                    "metadata": {}
                }
            ], 
            "execution_count": 45
        }, 
        {
            "source": "resized_tensor=initial_tensor.view(3,2)\nresized_tensor.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.Size([3, 2])"
                    }, 
                    "execution_count": 46, 
                    "metadata": {}
                }
            ], 
            "execution_count": 46
        }, 
        {
            "source": "resized_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.7834, 0.1569],\n        [0.1111, 0.3895],\n        [0.3012, 0.3274]])"
                    }, 
                    "execution_count": 47, 
                    "metadata": {}
                }
            ], 
            "execution_count": 47
        }, 
        {
            "source": "resized_matrix=initial_tensor.view(-1,2)\nresized_matrix.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.Size([3, 2])"
                    }, 
                    "execution_count": 48, 
                    "metadata": {}
                }
            ], 
            "execution_count": 48
        }, 
        {
            "source": "initial_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.7834, 0.1569, 0.1111],\n        [0.3895, 0.3012, 0.3274]])"
                    }, 
                    "execution_count": 49, 
                    "metadata": {}
                }
            ], 
            "execution_count": 49
        }, 
        {
            "source": "sorted_tensor,sorted_indices=torch.sort(initial_tensor)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 50
        }, 
        {
            "source": "sorted_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.1111, 0.1569, 0.7834],\n        [0.3012, 0.3274, 0.3895]])"
                    }, 
                    "execution_count": 51, 
                    "metadata": {}
                }
            ], 
            "execution_count": 51
        }, 
        {
            "source": "sorted_indices", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[2, 1, 0],\n        [1, 2, 0]])"
                    }, 
                    "execution_count": 52, 
                    "metadata": {}
                }
            ], 
            "execution_count": 52
        }, 
        {
            "source": "sorted_tensor,sorted_indices=torch.sort(initial_tensor,dim=0)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 53
        }, 
        {
            "source": "sorted_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[0.3895, 0.1569, 0.1111],\n        [0.7834, 0.3012, 0.3274]])"
                    }, 
                    "execution_count": 54, 
                    "metadata": {}
                }
            ], 
            "execution_count": 54
        }, 
        {
            "source": "sorted_indices", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[1, 0, 0],\n        [0, 1, 1]])"
                    }, 
                    "execution_count": 55, 
                    "metadata": {}
                }
            ], 
            "execution_count": 55
        }, 
        {
            "source": "Similar to TF graphs but with one important difference:pytorch computation graphs are dynamic ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from torch.autograd import Variable ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 57
        }, 
        {
            "source": "x=Variable(torch.randn(1,10))\nh=Variable(torch.randn(1,20))\nW_h=Variable(torch.randn(20,20))\nW_x=Variable(torch.randn(20,10))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 59
        }, 
        {
            "source": "h_prod=torch.mm(W_h,h.t())\nx_prod=torch.mm(W_x,x.t())\nnext_h=(h_prod+x_prod).tanh()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 61
        }, 
        {
            "source": "loss=next_h.sum()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 65
        }, 
        {
            "source": "loss.backward()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "element 0 of tensors does not require grad and does not have a grad_fn", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-66-684559e268b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m~/user-libs/python3/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m~/user-libs/python3/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
                    ], 
                    "ename": "RuntimeError"
                }
            ], 
            "execution_count": 66
        }, 
        {
            "source": "Building a Simple NN  Model ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "loss=0=Ypredice-Yactual", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "tensor=torch.Tensor([[3,4],[7,5]])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 67
        }, 
        {
            "source": "tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[3., 4.],\n        [7., 5.]])"
                    }, 
                    "execution_count": 68, 
                    "metadata": {}
                }
            ], 
            "execution_count": 68
        }, 
        {
            "source": "tensor.requires_grad", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "False"
                    }, 
                    "execution_count": 69, 
                    "metadata": {}
                }
            ], 
            "execution_count": 69
        }, 
        {
            "source": "tensor.requires_grad_()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[3., 4.],\n        [7., 5.]], requires_grad=True)"
                    }, 
                    "execution_count": 70, 
                    "metadata": {}
                }
            ], 
            "execution_count": 70
        }, 
        {
            "source": "tensor.requires_grad", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "True"
                    }, 
                    "execution_count": 71, 
                    "metadata": {}
                }
            ], 
            "execution_count": 71
        }, 
        {
            "source": "print(tensor.grad_fn)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "None\n"
                }
            ], 
            "execution_count": 72
        }, 
        {
            "source": "out=tensor*tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 73
        }, 
        {
            "source": "out.requires_grad", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "True"
                    }, 
                    "execution_count": 74, 
                    "metadata": {}
                }
            ], 
            "execution_count": 74
        }, 
        {
            "source": "print(out.grad)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "None\n"
                }
            ], 
            "execution_count": 75
        }, 
        {
            "source": "print(out.grad_fn)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<ThMulBackward object at 0x7f6068b29390>\n"
                }
            ], 
            "execution_count": 76
        }, 
        {
            "source": "print(tensor.grad_fn)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "None\n"
                }
            ], 
            "execution_count": 77
        }, 
        {
            "source": "out=(tensor*tensor.mean())\nprint(out.grad_fn)\nout.backward", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<ThMulBackward object at 0x7f6068b29860>\n"
                }
            ], 
            "execution_count": 78
        }, 
        {
            "source": "print(tensor.grad)#\u4e0a\u9762\u90a3\u4e2a\u4e0d\u8d77\u4f5c\u7528", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "None\n"
                }
            ], 
            "execution_count": 80
        }, 
        {
            "source": "import numpy as np \nimport matplotlib.pyplot as plt", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 84
        }, 
        {
            "source": "x_train =torch.from_numpy(x_train)\ny_train=torch.from_numpy(y_train)\n\nprint(\"require grad for x_train\",x_train.requires_grad)\nprint(\"require grad for x_train\",y_train.requires_grad)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "input_size=1\nhidden_size=100\noutput_size=1\nlearning_rate=1e-6", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 89
        }, 
        {
            "source": "w1=torch.rand(input_size,\n              hidden_size,\n              requires_grad=True)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 90
        }, 
        {
            "source": "w1.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "torch.Size([1, 100])"
                    }, 
                    "execution_count": 91, 
                    "metadata": {}
                }
            ], 
            "execution_count": 91
        }, 
        {
            "source": "w2=torch.rand(input_size,\n              hidden_size,\n              requires_grad=True)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 92
        }, 
        {
            "source": "for iter in range(1,301):\n    y_pred=x_train.mm(w1).clamp(min=0).mm(w2)\n    loss=(y_pred-y_train).pow(2).sum()\n    \n    if iter % 50==0:\n        print(iter,loss.item())\n        \n    loss.backward()\n    \n    with torch.no_grad():\n        w1-=learning_rate*w1.grad\n        w2-=learning_rate*w2.grad\n        w1.grad.zero_()\n        w2.grad.zero_()\n    \n    ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "print(\"w1\":w1)\nprint(\"w2\":w2)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "x_train_tensor=torch.from_numpy(x_train)\nx_train_tensor", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "predicted=predicted_in_tensor.detach().numpy()\npredicted", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "plt.plot(x_train,y_train,\"ro\",label=\"Original data\")\n\nplt.plot(x_train,predicted,label='Fitted line')\n\nplt.legend()\n\nplt.show()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_d068585ca6794db3b83ed62bd18a12d1 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='Ww3cQB_4dE6bYMEtxvJiEd1mSujEGfdX5z3EEfgQZIjC',\n    ibm_auth_endpoint=\"https://iam.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_d068585ca6794db3b83ed62bd18a12d1.get_object(Bucket='pyspark2-donotdelete-pr-u6kv1cpq61thty',Key='names.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nnames_data  = pd.read_csv(body)\nnames_data .head()\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aamir</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aaron</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aaron</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abagael</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abagail</td>\n      <td>Female</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "      Name  Gender\n0    Aamir    Male\n1    Aaron  Female\n2    Aaron    Male\n3  Abagael  Female\n4  Abagail  Female"
                    }, 
                    "execution_count": 9, 
                    "metadata": {}
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "len(names_data)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "10132"
                    }, 
                    "execution_count": 10, 
                    "metadata": {}
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "len(names_data['Name'].unique())", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "9543"
                    }, 
                    "execution_count": 12, 
                    "metadata": {}
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "import random \nnames_data = names_data.drop_duplicates(subset=['Name'], \n                                        keep=random.choice(['first', 'last']))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 14
        }, 
        {
            "source": "names_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aamir</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aaron</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abagael</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abagail</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Abbe</td>\n      <td>Female</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "      Name  Gender\n0    Aamir    Male\n2    Aaron    Male\n3  Abagael  Female\n4  Abagail  Female\n5     Abbe  Female"
                    }, 
                    "execution_count": 15, 
                    "metadata": {}
                }
            ], 
            "execution_count": 15
        }, 
        {
            "source": "from sklearn import preprocessing \nle=preprocessing.LabelEncoder()\nnames_data['Gender']=le.fit_transform(names_data['Gender'])\nnames_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  app.launch_new_instance()\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aamir</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aaron</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abagael</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abagail</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Abbe</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "      Name  Gender\n0    Aamir       1\n2    Aaron       1\n3  Abagael       0\n4  Abagail       0\n5     Abbe       0"
                    }, 
                    "execution_count": 16, 
                    "metadata": {}
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "#le\u3002fit_transform \u8bb0\u4f4f\u5982\u4f55\u4f7f\u7528\u8fd9\u4e2a", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "genders=['Female','Male']", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 17
        }, 
        {
            "source": "import string \nall_letters=string.ascii_letters+\".,;'\"\nn_letters=len(all_letters)\nall_letters", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,;'\""
                    }, 
                    "execution_count": 18, 
                    "metadata": {}
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "# function to convert name in tensors \n#this effectively performs one-hot-encoding \nimport torch \ndef name_to_tensor(name):\n    name_in_tensor=torch.zeros(len(name),1,n_letters)\n    for i,letter in enumerate(name):\n        name_in_tensor[i][0][all_letters.find(letter)]=1\n    return name_in_tensor ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 19
        }, 
        {
            "source": "name_to_tensor('jone')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0.]]])"
                    }, 
                    "execution_count": 20, 
                    "metadata": {}
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "#define the RNN \nimport torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        combined = torch.cat((input, hidden), 1)\n        hidden = self.i2h(combined)    \n        output = self.i2o(combined)    \n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 21
        }, 
        {
            "source": "#create an RNN \nn_hidden = 128\nn_genders= len(genders)\n\nrnn = RNN(n_letters, n_hidden, output_size = n_genders)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 22
        }, 
        {
            "source": "#define the parameters for training the model \niterations=100000\ncriterion=nn.NLLLoss()\nlearning_rate=0.005", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 23
        }, 
        {
            "source": "#convert a prediction to the string label for gender \ndef output_to_gender (output):\n    \n    top_n, top_index = output.topk(1)\n    pred_i = top_index[0].item()\n    pred = genders[pred_i] \n    \n    return pred", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 24
        }, 
        {
            "source": "import random", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 25
        }, 
        {
            "source": "for iteration in range(1 , iterations +1):\n\n    i = random.randint(0, len(names_data) - 1)\n    \n    name = names_data.iloc[i][0]\n    name_in_tensor = name_to_tensor(name)\n    \n    gender = names_data.iloc[i][1]\n    gender_in_tensor = torch.LongTensor([gender])\n    \n    hidden = rnn.initHidden()\n    rnn.zero_grad()\n\n    for i in range(name_in_tensor.size()[0]):\n        output, hidden = rnn(name_in_tensor[i], hidden)\n\n    loss = criterion(output, gender_in_tensor)\n    loss.backward()\n    \n    for p in rnn.parameters():\n        p.data.add_(-learning_rate, p.grad.data)\n\n    if iteration% 5000 == 0:\n        \n        pred = output_to_gender(output)\n        \n        correct = '\u2713' if pred == genders[gender] else '\u2717 (%s)' % genders[gender]\n        print('iters- %d %d%% (%s) Name- %s Gender- %s %s' % \\\n              (iteration, iteration/iterations*100, loss.item(), name, pred, correct))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "iters- 5000 5% (0.8627834320068359) Name- Terri Gender- Female \u2717 (Male)\niters- 10000 10% (0.5916165113449097) Name- Perry Gender- Male \u2713\niters- 15000 15% (0.4957372844219208) Name- Danyell Gender- Female \u2713\niters- 20000 20% (0.11897659301757812) Name- Benoite Gender- Female \u2713\niters- 25000 25% (0.005750894546508789) Name- Madelina Gender- Female \u2713\niters- 30000 30% (0.03524589538574219) Name- Gusta Gender- Female \u2713\niters- 35000 35% (0.21323752403259277) Name- Marie Gender- Female \u2713\niters- 40000 40% (0.5342760682106018) Name- Chandal Gender- Female \u2713\niters- 45000 45% (0.0014083385467529297) Name- Natalya Gender- Female \u2713\niters- 50000 50% (1.1558303833007812) Name- Akiko Gender- Male \u2717 (Female)\niters- 55000 55% (1.1959596872329712) Name- Waly Gender- Male \u2717 (Female)\niters- 60000 60% (0.24575191736221313) Name- Candance Gender- Female \u2713\niters- 65000 65% (0.09537744522094727) Name- Rycca Gender- Female \u2713\niters- 70000 70% (0.7235228419303894) Name- Wrennie Gender- Male \u2717 (Female)\niters- 75000 75% (0.05263638496398926) Name- Ellene Gender- Female \u2713\niters- 80000 80% (0.00493621826171875) Name- Teena Gender- Female \u2713\niters- 85000 85% (0.5093424916267395) Name- Wilmette Gender- Female \u2713\niters- 90000 90% (0.12277257442474365) Name- Willdon Gender- Male \u2713\niters- 95000 95% (0.003304719924926758) Name- Deanna Gender- Female \u2713\niters- 100000 100% (0.20287948846817017) Name- Elliot Gender- Male \u2713\n"
                }
            ], 
            "execution_count": 26
        }, 
        {
            "source": "#perform a test using 10000 randomly selected names \nn_confusion = 10000\n\nprediction=[]\nactual = []\n\nfor _ in range(n_confusion):\n\n    i = random.randint(0, len(names_data) - 1)\n    \n    name = names_data.iloc[i][0]\n    name_in_tensor = name_to_tensor(name)\n    \n    gender_idx = names_data.iloc[i][1]\n    gender_in_tensor = torch.LongTensor([gender_idx])\n        \n    hidden = rnn.initHidden()\n\n    for j in range(name_in_tensor.size()[0]):\n        output, hidden = rnn(name_in_tensor[j], hidden)\n    \n    pred = output_to_gender(output)\n    \n    prediction.append(pred)\n    actual.append(genders[gender_idx])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 27
        }, 
        {
            "source": "!pip install pandas_ml", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting pandas_ml\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/72/6d90debfcb9ea74ec00927fa7ed0204dcc560b1f9ffcd8b239daa7fd106d/pandas_ml-0.6.1-py3-none-any.whl (100kB)\n\u001b[K    100% |################################| 102kB 3.1MB/s ta 0:00:01\n\u001b[?25hCollecting enum34 (from pandas_ml)\n  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\nCollecting pandas>=0.19.0 (from pandas_ml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/a3/c42cd52e40527ba35aed53a988c485ffeddbae0722b8b756da82464baa73/pandas-0.24.1-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\n\u001b[K    100% |################################| 10.0MB 1.3MB/s eta 0:00:01\n\u001b[?25hCollecting python-dateutil>=2.5.0 (from pandas>=0.19.0->pandas_ml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n\u001b[K    100% |################################| 235kB 3.5MB/s eta 0:00:01\n\u001b[?25hCollecting numpy>=1.12.0 (from pandas>=0.19.0->pandas_ml)\n  Using cached https://files.pythonhosted.org/packages/e3/18/4f013c3c3051f4e0ffbaa4bf247050d6d5e527fe9cb1907f5975b172f23f/numpy-1.16.2-cp35-cp35m-manylinux1_x86_64.whl\nCollecting pytz>=2011k (from pandas>=0.19.0->pandas_ml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl (510kB)\n\u001b[K    100% |################################| 512kB 2.9MB/s eta 0:00:01\n\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.5.0->pandas>=0.19.0->pandas_ml)\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n\u001b[31mpyspark 2.3.0 requires py4j==0.10.6, which is not installed.\u001b[0m\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\nInstalling collected packages: enum34, six, python-dateutil, numpy, pytz, pandas, pandas-ml\nSuccessfully installed enum34-1.1.6 numpy-1.16.2 pandas-0.24.1 pandas-ml-0.6.1 python-dateutil-2.8.0 pytz-2018.9 six-1.12.0\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/six-1.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/numpy-1.16.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
                }
            ], 
            "execution_count": 29
        }, 
        {
            "source": "from pandas_ml import ConfusionMatrix\nimport numpy as np ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 30
        }, 
        {
            "source": "np_prediction = np.array(prediction)\nnp_actual = np.array(actual)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 31
        }, 
        {
            "source": "cm = ConfusionMatrix(np.where(np_prediction == 'Female', True, False), \n                     np.where(np_actual == 'Female', True, False))\ncm", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Predicted  False  True  __all__\nActual                         \nFalse       2416   897     3313\nTrue         870  5817     6687\n__all__     3286  6714    10000"
                    }, 
                    "execution_count": 32, 
                    "metadata": {}
                }
            ], 
            "execution_count": 32
        }, 
        {
            "source": "import matplotlib.pyplot as plt\ncm.plot(normalized=True)\nplt.show()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x2b87ed0c0be0>"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 33
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}